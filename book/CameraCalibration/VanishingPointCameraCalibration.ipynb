{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrinsic Camera Calibration \n",
    "\n",
    "Sensor calibration is one of the most important aspects of building a robot. Different sensors have differnt callibration procedures. For this chapter, we would be focusing on extrinsic camera calibration. \n",
    "\n",
    "Refer back to the ['From Pixels to Meters'](https://thomasfermi.github.io/Algorithms-for-Automated-Driving/LaneDetection/InversePerspectiveMapping.html) chapter. If you did the excersices of that chapter, you may recall that to covert the lane line pixels detected by the neural network to meters, the rotation matrix $\\mathbf{R_{cr}}$ was required that described how the camera was oriented with respect to the road. $\\mathbf{R_{cr}}$ was very easy to obtain through the CARLA simulator. But this may not be that easy in real life to obtain $\\mathbf{R_{cr}}$. The road is also not flat in real life mostly as the road can be banked, elevated or just uneven and therefore, the orientaion of the car and the camera keeps changing with respect to the flat road frame. The orientation of car and camera may also change with respect to the road if car breaks are hit hard or due to the car suspension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing Point Method\n",
    "\n",
    "We know that the rail tracks or the lane lines are mostly parallel, however, if we take an image of the track or road from a camera, we would observe that the track lines or the lanes are not parallel in the image. The point where these lines intersect in an image is known as the vanishing point.\n",
    "\n",
    "```{figure} images/vanishing_point.png\n",
    "---\n",
    "width: 50%\n",
    "name: vanishing_point_carla\n",
    "---\n",
    "```\n",
    "\n",
    "```{figure} images/Vanishing_point.svg\n",
    "---\n",
    "width: 50%\n",
    "name: vanishing_point\n",
    "---\n",
    "Image Source [wikipedia](https://en.wikipedia.org/wiki/Vanishing_point)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that, in the world co-ordinate system, these parallel lines won't ever intersect. So we assusme that the vanishing point is at infinity. This can be represented by \n",
    "\n",
    "$$ \\mathbf{Z_{\\infty}} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} $$\n",
    "\n",
    "$ \\mathbf{Z_{\\infty}}$ is the vanishing point in z-direction in homogeneous coordinates. $Z$ direction is defined by the direction of the lanes (forward).\n",
    "\n",
    "Now, let the co-ordinates of vanishing point in image space be $\\mathbf{u}$ and $\\mathbf{v}$ which can be represented by $\\mathbf{p_{\\infty}}$. We know that \n",
    "\n",
    "$$\n",
    "    \\lambda \\mathbf{p_{\\infty}} = \\mathbf{K} \\begin{pmatrix} \\mathbf{R} | \\mathbf{t} \\end{pmatrix} \\mathbf{Z_{\\infty}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\lambda \\mathbf{p_{\\infty}} = \\mathbf{K} \\begin{pmatrix} R_{xx}  R_{xy}  R_{xz}  t_x \\\\ R_{yx}  R_{yy}  R_{yz}  t_y \\\\ R_{zx}  R_{zy}  R_{zz}  t_z \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, multiplying transformation matrix with $\\mathbf{Z_{\\infty}}$ will eliminate 1st, 2nd and 4th columnns leaving us with only 3rd column whose values are $\\mathbf{R_{xz}}$, $\\mathbf{R_{yz}}$  and $\\mathbf{R_{zz}}$. Let us denote this by ${r_{3}}$.\n",
    "\n",
    "Solving for ${r_{3}}$, we get\n",
    "\n",
    "$$\n",
    "    \\lambda \\mathbf{p_{\\infty}} = \\mathbf{K} \\mathbf{r_{3}}\n",
    "$$\n",
    "\n",
    "\n",
    "Since columns of a rotation matrix are vectors with length 1 (unit vectors). Thus, $\\lambda$ equals to $\\frac{1} {\\| \\mathbf{K}^{-1} \\mathbf{p_{\\infty}}\\| }$. Therefore, \n",
    "\n",
    "$$\n",
    "    {r_{3}} = \\frac{\\mathbf{K}^{-1} \\mathbf{p_{\\infty}}} {\\| \\mathbf{K}^{-1} \\mathbf{p_{\\infty}}\\| }\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the vanishing point method, we are able to only recover $\\mathbf{r_{3}}$ which would be able to yield **yaw** and **pitch** of the camera. It makes intuitive sense that the vanishing point method is not able to recover **roll** and **translation** becuse vanishing point is not affected by these two! Imaging looking at a star. The star's position is only going to change if you change the yaw and pitch of your head and is not affected by roll and translation. The stars move with you when you are travelling in the car, therefore no change. Same goes with roll.\n",
    "\n",
    "\n",
    "```{figure} images/car_rpy.svg\n",
    "---\n",
    "width: 60%\n",
    "name: coordinate_system\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand this by an example from CARLA. \n",
    "\n",
    "### Changing Roll\n",
    "\n",
    "````{tabbed} roll = -20°\n",
    "```{figure} images/images_vp/p-0-y-0-r-20.png\n",
    "---\n",
    "width: 90%\n",
    "name: roll_minus_20\n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} roll = 0°\n",
    "```{figure} images/images_vp/p-0-y-0.png\n",
    "---\n",
    "width: 90%\n",
    "name: roll_0 \n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} roll = 20°\n",
    "```{figure} images/images_vp/p-0-y-0-r--20.png\n",
    "---\n",
    "width: 90%\n",
    "name: roll_20\n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "See that the vanishng point didn't change. Similarly, let's see if this also holds true for translation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Changing Translation\n",
    "\n",
    "````{tabbed} translation = -2 m\n",
    "```{figure} images/images_vp/trans--2.png\n",
    "---\n",
    "width: 90%\n",
    "name: translation_minus_2\n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} translation = 0 m\n",
    "```{figure} images/images_vp/p-0-y-0.png\n",
    "---\n",
    "width: 90%\n",
    "name: translation_0\n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} translation = 2 m\n",
    "```{figure} images/images_vp/trans-2.png\n",
    "---\n",
    "width: 90%\n",
    "name: translation_2\n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "You can see that the vanishing point lies at same position for all the above images. This shows that roll and translation won't affect the vanishing point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now let's see the affect of changing pitch and yaw.\n",
    "\n",
    "### Changing Pitch\n",
    "\n",
    "````{tabbed} pitch = -5°\n",
    "```{figure} images/images_vp/p--5-y-0.png\n",
    "---\n",
    "width: 90%\n",
    "name: pitch_minus_5\n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} pitch = 0°\n",
    "```{figure} images/images_vp/p-0-y-0.png\n",
    "---\n",
    "width: 90%\n",
    "name: pitch_0\n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} pitch = 5°\n",
    "```{figure} images/images_vp/p-5-y-0.png\n",
    "---\n",
    "width: 90%\n",
    "name: pitch_5\n",
    "---\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Yaw\n",
    "\n",
    "````{tabbed} yaw = -5°\n",
    "```{figure} images/images_vp/p-0-y--10.png\n",
    "---\n",
    "width: 90%\n",
    "name: yaw_minus_5\n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} yaw = 0°\n",
    "```{figure} images/images_vp/p-0-y-0.png\n",
    "---\n",
    "width: 90%\n",
    "name: yaw_0\n",
    "---\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} yaw = 5°\n",
    "```{figure} images/images_vp/p-0-y-10.png\n",
    "---\n",
    "width: 90%\n",
    "name: yaw_5\n",
    "---\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vanishing point shifted in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving Yaw and pitch from vanishing point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We derived and discussed about the rotation matrix in `Basis of Image Formation` section of the `Lane Detection` chapter. The Trasnformation matrix with respect to yaw, pitch and roll is given by \n",
    "\n",
    "$$\n",
    "    {R} = R_{yaw}R_{picth}R_{roll}\n",
    "$$\n",
    "\n",
    "$$\n",
    "   {R} = \\begin{pmatrix} \\cos(\\gamma)\\cos(\\beta) + \\sin(\\alpha)\\sin(\\gamma)\\sin(\\beta)  & \\cos(\\gamma)\\sin(\\alpha)\\sin(\\beta) -\\cos(\\beta)\\sin(\\gamma) & -\\cos(\\alpha)\\sin(\\beta)  \\\\\n",
    "                          \\cos(\\alpha)\\sin(\\gamma) & \\cos(\\alpha)\\cos(\\gamma) & \\sin(\\alpha)  \\\\\n",
    "                          \\cos(\\gamma)\\sin(\\beta) -\\cos(\\beta)\\sin(\\alpha)\\sin(\\gamma)  & -\\cos(\\gamma)\\cos(\\beta)\\sin(\\alpha) -\\sin(\\gamma)\\sin(\\beta)  & \\cos(\\alpha)\\cos(\\beta) \\\\\n",
    "                            \\end{pmatrix} \n",
    "$$\n",
    "\n",
    "$\\alpha, \\beta, \\gamma$ are the pitch, yaw, and roll angles respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third row of this rotation matrix is\n",
    "\n",
    "$$\n",
    "   r_{3} = \\begin{pmatrix}  -\\cos(\\alpha)\\sin(\\beta) \\\\\n",
    "                            \\sin(\\alpha) \\\\\n",
    "                            \\cos(\\alpha)\\cos(\\beta) \\\\\n",
    "                            \\end{pmatrix} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$\n",
    "    r_{3} = \\begin{pmatrix}  -\\cos(\\alpha)\\sin(\\beta) \\\\\n",
    "                            \\sin(\\alpha) \\\\\n",
    "                            \\cos(\\alpha)\\cos(\\beta) \\\\\n",
    "                            \\end{pmatrix}  = \\frac{\\mathbf{K}^{-1} \\mathbf{p_{\\infty}}} {\\| \\mathbf{K}^{-1} \\mathbf{v_{\\infty}}\\| }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving for $\\alpha$ and $\\beta$ we get:\n",
    "\n",
    "$$\n",
    "    \\beta = -\\tan^{-1}\\frac{{r_{3}}(1)}{{r_{3}}(3)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\alpha = \\sin^{-1}{{r_{3}}(2)}\n",
    "$$\n",
    "\n",
    "We have now derived pitch and yaw from vanishing point! Now let's dive into the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/test.png')[:, :, (2, 1, 0)]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using our lane detector network trained previously to find points of the left and right lane. This image was collected from CARLA having a pitch of -5 degrees and yaw of -2 degrees. \n",
    "\n",
    "One thing to note here is, we are finding orrientation of camera with respect to the car and not car with respect to the lane before calibrating. Therefore, the car needs to be alligned with respect to the lane line. Therefore, the camera calibration test is usually done when the car is driving **fast and straight**. This ensures that the car is alligned with respect to the lanes. Several autonomous driving softwares like tesla's autopilot, comma ai's openpilot and many more require you to drive fast and straight to calibrate the cameras before you can engage the software to drive the car.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../code')\n",
    "from solutions.camera_calibration.calibrated_lane_detector import CalibratedLaneDetector\n",
    "from solutions.camera_calibration.calibrated_lane_detector import get_intersection, get_py_from_vp\n",
    "from pathlib import Path\n",
    "\n",
    "model_path = Path(\"../../code/solutions/lane_detection/best_model_multi_dice_loss.pth\")\n",
    "cld = CalibratedLaneDetector(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, left_prob, right_prob = cld.detect(img)\n",
    "poly_left, poly_right = cld._fit_line_v_of_u(left_prob), cld._fit_line_v_of_u(right_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lane detector gives out a segmentation mask of the lane lines which is used to fit a one degree polynomial of the form $y = mx  + c$ since vanishing point is calculated from straight lines and not curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two lines will intersect at $x = x_{i}$ and $y = y_{i}$\n",
    "\n",
    "$$\n",
    "    m_{1}x_{i} + c_{1} = m_{2}x_{i} + c_{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    x_{i} = \\frac{c_{2} - c_{1}}{m_{1} - m_{2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    y_{i} = m_{1}x_{i} + c_{1} \n",
    "$$\n",
    "$$\n",
    "or\n",
    "$$\n",
    "$$\n",
    "    y_{i} = m_{2}x_{i} + c_{2}\n",
    "$$\n",
    "\n",
    "The intersection of lane lines in the image space gives us the vanishing point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_i, v_i = get_intersection(poly_left, poly_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image\n",
    "plt.imshow(img)\n",
    "\n",
    "# plot detected lane lines\n",
    "u = np.arange(0, cld.cg.image_width, 1)\n",
    "v_left = poly_left(u)\n",
    "v_right = poly_right(u)\n",
    "\n",
    "plt.plot(u, v_left, '-c')\n",
    "plt.plot(u, v_right, '-c')\n",
    "plt.xlim(0, cld.cg.image_width)\n",
    "plt.ylim(cld.cg.image_height, 0)\n",
    "\n",
    "# plot intersection of lane lines\n",
    "plt.scatter([u_i], [v_i], marker=\"o\", s=100, color=\"y\", zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can find pitch and yaw of the camera form the vanising point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions.lane_detection.camera_geometry import get_intrinsic_matrix\n",
    "\n",
    "fov, width, height = 45, 1024, 512\n",
    "K = get_intrinsic_matrix(fov, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pitch, yaw = get_py_from_vp(u_i, v_i, K)\n",
    "\n",
    "print(f'yaw degrees %.2f' % np.rad2deg(yaw))\n",
    "print(f'pitch degrees %.2f' % np.rad2deg(pitch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! You can expect small errors in yaw and pitch because small errors in lane detection can lead to large errors for the vanishing point. Therefore, the readings are mostly taken for a period of time from a video stream and averaged out at the end. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Now your task is to do the same thing. We provide you with one video. Your task is to use the lane detection network to calibrate the camera and output the yaw and pitch values.\n",
    "\n",
    "The video can be found in `data` folder and is named `calibration_video.mp4`.\n",
    "\n",
    "To start working on the exercises, open `code/tests/camera_calibration/calibration.ipynb` and follow the instructions in that notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
