{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_student_code = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(str(Path('../../')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_student_code:\n",
    "    from exercises.camera_calibration.calibrated_lane_detector import CalibratedLaneDetector, get_intersection, get_py_from_vp\n",
    "else:\n",
    "    from solutions.camera_calibration.calibrated_lane_detector import CalibratedLaneDetector, get_intersection, get_py_from_vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change the next line(s), to create an instance of *your* LaneDetector\n",
    "model_path = Path(\"../../solutions/lane_detection/best_model_multi_dice_loss.pth\")\n",
    "ld = CalibratedLaneDetector(model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change to another picture for which we know pitch and yaw. Maybe should have pitch -4, and yaw 2.5 \n",
    "image_fn = str(Path(\"../../../data/Town04_Clear_Noon_09_09_2020_14_57_22_frame_625_validation_set.png\"))\n",
    "image = cv2.imread(image_fn)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we detect the left and right boundaries as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, left_probs, right_probs = ld.detect(image)\n",
    "# just to visualize both detections (left and right) in one image we add them up\n",
    "plt.imshow(left_probs + right_probs, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit straight lines to the left and right boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_left  = ld._fit_line_v_of_u(left_probs)\n",
    "line_right = ld._fit_line_v_of_u(right_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the straight lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detected_lines(line_left, line_right):\n",
    "    u = np.arange(0,ld.cg.image_width, 1)\n",
    "    v_left = line_left(u)\n",
    "    v_right = line_right(u)\n",
    "\n",
    "    plt.plot(u,v_left, color='r')\n",
    "    plt.plot(u,v_right, color='b')\n",
    "    plt.xlim(0,ld.cg.image_width)\n",
    "    plt.ylim(ld.cg.image_height,0)\n",
    "\n",
    "plt.imshow(left_probs + right_probs, cmap=\"gray\")\n",
    "plot_detected_lines(line_left, line_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the vanishing point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanishing_point = get_intersection(line_left, line_right)\n",
    "print(vanishing_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the vanishing point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_i, v_i = vanishing_point\n",
    "plt.scatter([u_i],[v_i], marker=\"o\", s=100, color=\"c\", zorder=10)\n",
    "plt.imshow(left_probs + right_probs, cmap=\"gray\")\n",
    "plot_detected_lines(line_left, line_right)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally determine pitch and yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch, yaw = get_py_from_vp(u_i, v_i, ld.cg.intrinsic_matrix)\n",
    "print(\"pitch = \", np.rad2deg(pitch))\n",
    "print(\"yaw = \",  np.rad2deg(yaw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image in video:\n",
    "#   ld.calibrate(video)\n",
    "\n",
    "filename = Path(\"../../../data/calibration_video.mp4\")\n",
    "\n",
    "cap = cv2.VideoCapture(str(filename))\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    ld(image[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fe9c202b0db07198d9dcc7af04293ef8fbb00cb7b704bc35bc25acfd92023a0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
